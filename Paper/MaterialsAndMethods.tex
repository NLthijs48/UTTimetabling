\section{Materials and Methods}
\subsection{Given data}
For this project data about the time tables of the University of Twente is used, this data is provided by the University itself. The data is stored across a couple of \code{.xlsx} files, which can be used with \emph{Microsoft Excel}. There are separate files for the year 2013-2014 and the year 2014-2015. The following files have been provided:

\begin{itemize}
	\item \textbf{Activities:} Rows with the course name, lecture type, date (day, start/end time), teacher, group size, student sets, room
	\item \textbf{Course codes:} Rows with the activity name, description, course code, lecture type, date (day, start/end time) and group size
	\item \textbf{Teachers:} Rows with course code, course name, teacher code and teacher name
	\item \textbf{Usage counts:} Per activity of a certain day of the year a count of the number of people actually in the room.
	\item\textbf{Rooms:} Information about the available equipment in certain rooms
\end{itemize}

The activities and course codes files are actually used for the research in an automated way, the other files are only used to provide context.

\subsection{Excel to SQL}
To work with the provided data it has to be converted to a format that is easily to loop through or query in. The first step of the conversion is to get the data in a SQL database. The Excel file has been saved as tab-separated file through Excel itself. Then a Java program has been written to transform the tab-separated file into a SQL file that has insert statements for importing it into a database. This program first prints a \code{CREATE TABLE} statement to the output, which creates the table in the database with the correct columns. After this the program loops through the lines in the tab-separated file, performs a couple regular expressions on the line and adds it as an \code{INSERT} statement to the output.

The activities data conversion to SQL has just a couple steps, first filter forbidden characters like \code{'} and \code{"}, then replace all tabs by comma-space and as list add the start and end of the \code{INSERT} statement.

The courses data required more work, the main reason for this was that the data has a course code and a module code column. Normally only one of these should be filled in, the course code if it is an old course, the module code if it is a course in the new TOM model. This was however not true in practise, some activities had both and others had neither. Therefore extra corrections on the data have been made with regular expressions in addition to the corrections also made for the activities.

After the script converted the activities and courses data for both years to SQL scripts these have been imported in a PostgreSQL database. This database has been chosen because it is capable of generating XML with SQL queries.

\subsection{SQL to XML} \label{subsec:sql2xml}
From the SQL database the data has been exported as a couple XML databases. For both years a database with the activities and a database with the courses has been exported. The SQL query for generating the activities XML database can be found in Listing \ref{lst:sql2xml}. This database has been used for further querying with XQuery, which is described in Section \ref{subsec:xquery}. In order to get a valid XML database a root element had to be added to the output of the SQL query.

\begin{lstlisting}[caption=SQL to XML conversion, label=lst:sql2xml, float=htpb, language=sql]
select
	xmlelement(name "day",
		xmlforest(days.dateGiven, days.daygiven),
		(select
			xmlagg(xmlelement(name "activity",
				xmlforest(t.starttime, t.endtime, t.studentsets, t.room, t.coursename, t.teacher)
			))
		from
			ut1314 as t
		where
			days.dateGiven = t.dateGiven
		)
	)
from
	(select distinct
		t.dateGiven, t.daygiven
	from
		ut1314 as t
	order by
		t.dateGiven
) as days;
\end{lstlisting}

As shown in the query of Listing \ref{lst:sql2xml}, the data has been organized by day. So this means the XML database contains an element for each day, and this day element contains \code{<activity>} elements. Activity elements contain the course name/code, teacher, location, lecture type, etcetera. This organisation per day helped with the questions that would need to be answered. We for example investigated the number of wasted hours per day, which is defined as hours between lectures. So in this case having all activities of a day together is convenient. Some other questions did not rely on the day grouping, but also did not suffer because of this decision. More about this is explained in Section \ref{subsec:xquery}. The structure of the generated XML database can be found in Listing \ref{lst:xmlStructure}

\begin{lstlisting}[caption=XML structure, label=lst:xmlStructure, float=htpb]
<data>
	<day>
		<dateGiven>2013-08-23</dateGiven>
		<daygiven>Friday</daygiven>
		<activity>
			<startTime>08:45:00</startTime>
			<endTime>10:30:00</endTime>
			<studentsets>IDE M 1A A;CEM-CME M 1A A</studentsets>
			<room>HB 2A</room>
			<coursename>TW M2 Lineaire OptimalisatieZGB/06/01</coursename>
			<teacher>T.W. Wiefferink</teacher>
		</activity>
		...
	</day>
	...
</data>
\end{lstlisting}

\subsection{XQuery: gathering statistics} \label{subsec:xquery}
From the initial databases generated by the SQL queries, as discussed in Section \ref{subsec:sql2xml}, a couple of databases have been generated to specifically check the KPI's. The list below shows details about the generated databases. 

The source databases are generated by SQL, then there is a XQuery script to transform from these database to the top level items of the list. Then there is also a XQuery script for the transformation of each item to its children. In total there are 14 XQuery scripts for these transformations.

After generating the specific databases these are used to get the data for the KPI's. For this there is a XQuery script that goes through these databases and counts the number required for the KPI. The scripts itself can be found on GitHub\footnote{https://github.com/NLthijs48/UTTimetabling}, the data itself cannot be found there because the University of Twente asked to no publish it.

\textbf{Activities database:}
\begin{enumerate}
	\item Activities per day, student sets separated as different activities.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, student sets separated, classes extended by 15 minutes
	\begin{enumerate}
		\item Per day for each student the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per student set.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated, classes extended by 15 minutes.
	\begin{enumerate}
		\item Per day for each teacher the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per teacher.
		\end{enumerate}
	\end{enumerate}
	\item Per room the number of minutes it has been used.
\end{enumerate}

\textbf{Courses database:}
\begin{enumerate}
	\item Per quartile per course the number of planned minutes.
\end{enumerate}

\subsection{Per Quartile statistics and display}
To expand on the KPI statistics there has been an exploration of the data based on per quartile statistics. To generate statistics per quartile instead of per year (as with the KPI's) a Java program has been written. The goal is to show these statistics on a website with bar graphs per quartile. To generate files that can be displayed on a website Java is a good choice, since it can do a lot more than XQuery can. Since Java would already be used for generating the data for display on a website, and the fact that grouping results per quartile in XQuery is complicated, we decided to generate these statistics with Java instead.

As input for the Java program the XML databases as described in Section \ref{subsec:xquery} have been used. 





