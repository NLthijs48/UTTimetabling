\section{Materials and Methods}
\subsection{Given data}
For this project data about the time tables of the University of Twente is used, this data is provided by the University itself. The data is stored across a couple of \code{.xlsx} files, which can be used with \emph{Microsoft Excel}. There are separate files for the year 2013-2014 and the year 2014-2015. The following files have been provided:

\begin{itemize}
	\item \textbf{Activities:} Rows with the course name, lecture type, date (day, start/end time), teacher, group size, student sets, room
	\item \textbf{Course codes:} Rows with the activity name, description, course code, lecture type, date (day, start/end time) and group size
	\item \textbf{Teachers:} Rows with course code, course name, teacher code and teacher name
	\item \textbf{Usage counts:} Per activity of a certain day of the year a count of the number of people actually in the room (counted manually for a few days in the year).
	\item\textbf{Rooms:} Information about the available equipment in certain rooms
\end{itemize}

The activities and course codes files are actually used for the research in an automated way, the other files are only used to provide context.

\subsection{Excel to SQL}
To work with the provided data it has to be converted to a format that is easily to loop through or query in. The first step of the conversion is to get the data in a SQL database. The Excel file has been saved as tab-separated file through Excel itself. Then a Java program has been written to transform the tab-separated file into a SQL file that has insert statements for importing it into a database. This program first prints a \code{CREATE TABLE} statement to the output, which creates the table in the database with the correct columns. After this the program loops through the lines in the tab-separated file, performs a couple regular expressions on the line and adds it as an \code{INSERT} statement to the output.

The activities data conversion to SQL has just a couple steps, first filter forbidden characters like \code{'} and \code{"}, then replace all tabs by comma-space and as list add the start and end of the \code{INSERT} statement.

The courses data required more work, the main reason for this was that the data has a course code and a module code column. Normally only one of these should be filled in, the course code if it is an old course, the module code if it is a course in the new TOM model. This was however not true in practise, some activities had both and others had neither. Therefore extra corrections on the data have been made with regular expressions in addition to the corrections also made for the activities to merge the module and course codes into one column.

After the script converted the activities and courses data for both years to SQL scripts these have been imported in a PostgreSQL database. This database has been chosen because it is capable of generating XML with SQL queries.

\subsection{SQL to XML} \label{subsec:sql2xml}
From the SQL database the data has been exported as a couple XML databases. For both years a database with the activities and a database with the courses has been exported. The SQL query for generating the activities XML database can be found in Listing \ref{lst:sql2xml}. This database has been used for further querying with XQuery, which is described in Section \ref{subsec:xquery}. In order to get a valid XML database a root element had to be added to the output of the SQL query.

\begin{lstlisting}[caption=SQL to XML conversion, label=lst:sql2xml, float=htpb, language=sql]
select
	xmlelement(name "day",
		xmlforest(days.dateGiven, days.daygiven),
		(select
			xmlagg(xmlelement(name "activity",
				xmlforest(t.starttime, t.endtime, t.studentsets, t.room, t.coursename, t.teacher)
			))
		from
			ut1314 as t
		where
			days.dateGiven = t.dateGiven
		)
	)
from
	(select distinct
		t.dateGiven, t.daygiven
	from
		ut1314 as t
	order by
		t.dateGiven
) as days;
\end{lstlisting}

As shown in the query of Listing \ref{lst:sql2xml}, the data has been organized by day. So this means the XML database contains an element for each day, and this day element contains \code{<activity>} elements. Activity elements contain the course name/code, teacher, location, lecture type, etcetera. This organisation per day helped with the questions that would need to be answered. We for example investigated the number of wasted hours per day, which is defined as hours between lectures. So in this case having all activities of a day together is convenient. Some other questions did not rely on the day grouping, but also did not suffer because of this decision. More about this is explained in Section \ref{subsec:xquery}. The structure of the generated XML database can be found in Listing \ref{lst:xmlStructure}

\begin{lstlisting}[caption=XML structure, label=lst:xmlStructure, float=htpb]
<data>
	<day>
		<dateGiven>2013-08-23</dateGiven>
		<daygiven>Friday</daygiven>
		<activity>
			<startTime>08:45:00</startTime>
			<endTime>10:30:00</endTime>
			<studentsets>IDE M 1A A;CEM-CME M 1A A</studentsets>
			<room>HB 2A</room>
			<coursename>TW M2 Lineaire OptimalisatieZGB/06/01</coursename>
			<teacher>T.W. Wiefferink</teacher>
		</activity>
		...
	</day>
	...
</data>
\end{lstlisting}

\subsection{XQuery: gathering statistics} \label{subsec:xquery}
From the initial databases generated by the SQL queries, as discussed in Section \ref{subsec:sql2xml}, a couple of databases have been generated to specifically check the KPIs. The list below shows details about the generated databases. 

The source databases are generated by SQL, then there is a XQuery script to transform from these database to the top level items of the list. Then there is also a XQuery script for the transformation of each item to its children. In total there are 14 XQuery scripts for these transformations.

After generating the specific databases these are used to get the data for the KPIs. For this there is a XQuery script that goes through these databases and counts the number required for the KPI. The scripts itself can be found on GitHub\footnote{https://github.com/NLthijs48/UTTimetabling}, the data itself cannot be found there because the University of Twente asked to keep the data private.

\textbf{Activities database:}
\begin{enumerate}
	\item Activities per day, student sets separated as different activities.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, student sets separated, classes extended by 15 minutes
	\begin{enumerate}
		\item Per day for each student the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per student set.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated, classes extended by 15 minutes.
	\begin{enumerate}
		\item Per day for each teacher the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per teacher.
		\end{enumerate}
	\end{enumerate}
	\item Per room the number of minutes it has been used.
\end{enumerate}

\textbf{Courses database:}
\begin{enumerate}
	\item Per quartile per course the number of planned minutes.
\end{enumerate}

\subsection{Per Quartile statistics display}
To expand on the KPI statistics there has been an exploration of the data based on per quartile statistics. To generate statistics per quartile instead of per year (as with the KPIs) a Java program has been written. The goal is to show these statistics on a website with bar graphs per quartile. To generate files that can be displayed on a website Java is a good choice, since it can do a lot more than XQuery can. Since Java would already be used for generating the data for display on a website, and the fact that grouping results per quartile in XQuery is complicated, we decided to generate these statistics with Java instead.

We mainly looked at the hours that teacher and students have lectures. The first statistic shows counts of college hours per day of students sets, divided into a couple groups. The groups are \emph{less than 4 hours}, \emph{4-6 hours}, \emph{7-8 hours}, \emph{more as 8 hours}. For teachers the same statistics have been calculated. Next the number of wasted hours compared to lecture hours has been plotted. Lecture hours are the actual hours placed into the timetable, wasted hours are hours between the activities in the timetable. Both added together is the number of hours required to be spend on the university. These statistics can be used to compare the wasted hours with the useful hours. This statistic has been counted for students and teachers. Next there is a bar graph of the number of courses, student sets and teachers in each quartile. These are there to be able to correct the numbers of the other statistics. The number of times there is a lecture on Friday evening has also been plotted. As last there is a graph that shows for each quartile the distribution of lecture types. This means it is a stacked bar graph with the number of Lectures, Practicals, Tutorials, Exam hours, etcetera. This data is incomplete since the provided course data is (probably by accident) for 2013-2014 and 2015-2016, which means data for 2014-2015 is missing and the last year is not yet complete.

As input for the Java program the XML databases as described in Section \ref{subsec:xquery} have been used. The Java program reads the XML database it needs for a certain statistic, counts it per quartile and outputs a JavaScript file that contains the graphing code and data. The HighCharts\footnote{http://highcharts.com} graph library has been used to display the statistics on a website. The result is visible at \url{http://wiefferink.me/TimeTabling}. This library lets the user check all values, and for example turn certain parts off to be able too compare parts of the data easily.





