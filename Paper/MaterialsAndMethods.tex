\section{Materials and Methods}
\subsection{Given data}
For this project data consisting of the time tables of the University of Twente is used. This data was provided by the university itself. The data is stored in a couple of \code{.xlsx} files, which can be used with \emph{Microsoft Excel}. There are separate files for the year 2013-2014 and the year 2014-2015. The following files have been provided:

\begin{itemize}
	\item \textbf{Activities:} Rows with the course name, lecture type, date (day, start/end time), teacher, group size, student sets, room
	\item \textbf{Course codes:} Rows with the activity name, description, course code, lecture type, date (day, start/end time) and group size
	\item \textbf{Teachers:} Rows with course code, course name, teacher code and teacher name
	\item \textbf{Usage counts:} Per activity of a certain day of the year a count of the number of people actually in the room (counted manually for a few days in the year).
	\item\textbf{Rooms:} Information about the available equipment in certain rooms
\end{itemize}

The activities and course codes files are actually used for the research in an automated way, the other files are only used to provide context.

\subsection{Excel to SQL}
To work with the provided data, it has to be converted to a format that is easy to loop through or query in. The first step of the conversion is to get the data in an SQL database. In order to do this, the Excel file was saved as a tab-separated file through Excel itself. Then a Java program was written to transform the tab-separated file into an SQL file that contains insert statements for importing the data into a database. This program first prints a \code{CREATE TABLE} statement to the output, which creates the table in the database with the correct columns. After this, the program loops through the lines in the tab-separated file and performs a couple regular expressions on each line before adding it to an \code{INSERT} statement in the program's output.

Converting the activities data to SQL consists of just a couple steps. Firstly, filter forbidden characters like \code{'} and \code{"}. Secondly,  replace all tabs by comma-space. Lastly, add the start and end of the \code{INSERT} statement.

The courses data required more work. The main reason for this was that the data holds a course code and a module code column. Normally, just one of these should be filled in; the course code if it is an old course or the module code if it is a course in the new TOM model. However, in practice, this seemed not to be true. Some activities contained both a course code and a module code while others had neither one of them. Therefore extra corrections on the data have been made with regular expressions in addition to the corrections that already were made for the activities to merge the module and course codes into one column.

After the script converted the activities and courses data for both years to SQL statements, they were imported into a PostgreSQL database. This database was chosen because it is capable of generating XML with SQL queries.

\subsection{SQL to XML} \label{subsec:sql2xml}
From the SQL database, the data was transformed in multiple XML databases. For both years, a database of the activities and a database of the courses was generated. The SQL query for generating the activities XML database can be found in Listing \ref{lst:sql2xml}. This database was used for further querying with XQuery, which is described in Section \ref{subsec:xquery}. In order to get a valid XML database, a root element had to be added to the output of the SQL query.

\begin{lstlisting}[caption=SQL to XML conversion, label=lst:sql2xml, float=htpb, language=sql]
select
	xmlelement(name "day",
		xmlforest(days.dateGiven, days.daygiven),
		(select
			xmlagg(xmlelement(name "activity",
				xmlforest(t.starttime, t.endtime, t.studentsets, t.room, t.coursename, t.teacher)
			))
		from
			ut1314 as t
		where
			days.dateGiven = t.dateGiven
		)
	)
from
	(select distinct
		t.dateGiven, t.daygiven
	from
		ut1314 as t
	order by
		t.dateGiven
) as days;
\end{lstlisting}

As shown in the query of Listing \ref{lst:sql2xml}, the data was organized by day. This means the XML database contains an element for each day, and this day element contains \code{<activity>} elements. Activity elements contain the course name/code, teacher, location, lecture type, etcetera. This organisation per day was useful for the questions that were going to be answered. We, for example, investigated the number of wasted hours per day, which is defined as hours between lectures. So, in this case, having all activities of a day together is convenient. Some other questions did not rely on the day grouping, but also did not suffer because of this decision. More about this is explained in Section \ref{subsec:xquery}. The structure of the generated XML database can be found in Listing \ref{lst:xmlStructure}

\begin{lstlisting}[caption=XML structure, label=lst:xmlStructure, float=htpb]
<data>
	<day>
		<dateGiven>2013-08-23</dateGiven>
		<daygiven>Friday</daygiven>
		<activity>
			<startTime>08:45:00</startTime>
			<endTime>10:30:00</endTime>
			<studentsets>IDE M 1A A;CEM-CME M 1A A</studentsets>
			<room>HB 2A</room>
			<coursename>TW M2 Lineaire OptimalisatieZGB/06/01</coursename>
			<teacher>T.W. Wiefferink</teacher>
		</activity>
		...
	</day>
	...
</data>
\end{lstlisting}

\subsection{XQuery: gathering statistics} \label{subsec:xquery}
From the initial databases generated by the SQL queries, as discussed in Section \ref{subsec:sql2xml}, a couple of databases were generated to specifically check the KPIs. The list below shows details about the generated databases. 

The source databases are generated with SQL queries, followed by an XQuery script to transform from these databases the top level items of the list. Then there is another XQuery script for the transformation of each item into its children. In total, there are 14 XQuery scripts for these transformations.

After generating these specific databases, they were used to get the data for the KPIs. For this, there is an XQuery script that loops through these databases and counts the number required for the KPI. The scripts itself can be found on GitHub\footnote{https://github.com/NLthijs48/UTTimetabling}, the data itself cannot be found there since the University of Twente asked to keep the data private.

\textbf{Activities database:}
\begin{enumerate}
	\item Activities per day, student sets separated as different activities.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, student sets separated, classes extended by 15 minutes
	\begin{enumerate}
		\item Per day for each student the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per student set.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated.
	\begin{enumerate}
		\item Per day for each student set the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item Count of days that student sets have evening classes and next day early classes.
		\end{enumerate}
	\end{enumerate}
	\item Activities per day, teachers separated, classes extended by 15 minutes.
	\begin{enumerate}
		\item Per day for each teacher the contactminutes, collegeminutes and start/end time.
		\begin{enumerate}
			\item 'Wasted' minutes per teacher.
		\end{enumerate}
	\end{enumerate}
	\item Per room the number of minutes it has been used.
\end{enumerate}

\textbf{Courses database:}
\begin{enumerate}
	\item Per quartile per course the number of planned minutes.
\end{enumerate}

\subsection{Per Quartile statistics display}
To elaborate on the KPI statistics, an exploration of the data based on per quartile statistics was performed. To generate statistics per quartile instead of per year (as with the KPIs), a Java program was written. The goal is to show these statistics on a website with bar graphs per quartile. To generate files that can be displayed on a website Java is a good choice since it can do a lot more than XQuery. Since Java was already used for data visualisation on a website and the fact that grouping results per quartile in XQuery is complicated, we decided to generate these statistics with Java instead.

We mainly studied the hours that teacher and students have lectures. The first statistic shows counts of college hours per day of students sets, divided into groups for college hours between one and eleven. For teachers, the same statistics have been calculated. Next the number of wasted hours compared to lecture hours was plotted. Lecture hours are the actual hours placed into the timetable, wasted hours are hours between the activities in the time\allowbreak table. Both added together is the number of hours required to be present at the university. These statistics can be used to compare the wasted hours with the useful hours. This statistic has been counted for students and teachers. Next, there is a bar graph of the number of courses, student sets and teachers in each quartile. These are there in order to be able to correct the values of the other statistics. Furthermore, the number of times there is a lecture on Friday evening was plotted as well. Lastly, there is a graph that shows the distribution of lecture types for each quartile. This means it is a stacked bar graph with the number of Lectures, Practicals, Tutorials, Exam hours, etcetera. This data is incomplete since the provided course data is (probably by accident) for 2013-2014 and 2015-2016, which means data for 2014-2015 is missing and that the last year is not yet complete.

As input for the Java program, the XML databases as described in Section \ref{subsec:xquery} was used. The Java program reads the XML database it needs for a certain statistic, counts it per quartile and outputs a JavaScript file that contains the graphing code and data. The HighCharts\footnote{http://highcharts.com} graph library has been used to display the statistics on a website. The result is visible at \url{http://wiefferink.me/TimeTabling}. This library gives the user the ability to check and uncheck certain values, making it easy to display and compare the data that is of interest.





